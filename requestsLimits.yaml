# kube-scheduler uses requests of all containers to schedule a pod on a node (chooses a node using round-robin)
# But limits could be higher than the requests, and what if we have a node where the sum of all
# container limits are higher than the resources available on the machine?
# At this point, Kubernetes goes into something called an â€œovercommitted state".

# For cpu, k8s will ensure that containers get the requested cpu and will throttle the rest.
# Memory cannot be compressed, so Kubernetes needs to start making decisions on what containers 
# to terminate if the Node runs out of memory.
# Kubernetes looks for Pods that are using more resources than they requested. The prime candidates are 
# pods that have gone over their request but are still under their limit. If multiple 
# pods have gone over their requests, it will rank those pods based on priority and will terminate the 
# lowest priority pods first.

# In case a container tries to use more memory than its limit, container runtime takes the action 
# and kernal terminates that process with OUT OF MEMORY (OOM) error.

# Sample
apiVersion: v1
kind: Pod
metadata:
  name: frontend
spec:
  containers:
  - name: app
    image: images.my-company.example/app:v4
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
  - name: log-aggregator
    image: images.my-company.example/log-aggregator:v6
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"

# How Kubernetes applies Resource Requests and Limits
# The kubelet passes that container's requests and limits for memory and CPU to the container runtime.
# Container runtime configures cgroups of the kernal to apply these limits.

# The CPU limits defines the ceiling on how much cpu time a container/cgroup can use.
# CPU requests typically defines a weighting, which means when different cgroups compete with each other
# then cgroups with larger cpu requests are allocated more cpu time. 
# However, container runtimes don't terminate Pods or containers for excessive CPU usage.

# Memory request is used for Pod scheduling mainly. 
# The memory limit defines a memory limit for that cgroup. If the container tries to allocate more memory 
# than this limit, the Linux kernel out-of-memory subsystem activates and, typically, intervenes by 
# stopping one of the processes in the container that tried to allocate memory. If that process is the 
# container's PID 1, and the container is marked as restartable, Kubernetes restarts the container.